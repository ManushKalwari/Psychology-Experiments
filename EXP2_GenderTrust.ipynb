{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c250b-e0a5-4d12-8cb7-c0475889498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender Trust Game (Croson & Buchan 1999) – LangGraph Implementation\n",
    "# Baseline: faithful-to-paper design\n",
    "\n",
    "from dataclasses import dataclass, asdict, field\n",
    "from typing import List, Dict, Optional\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import pathlib\n",
    "import torch\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14545541-5ada-44b5-b7e6-4201e8429b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    offload_folder=\"offload\"\n",
    ")\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfb8e99-f040-4910-8209-11733f82e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Data models\n",
    "# -----------------------------\n",
    "\n",
    "@dataclass\n",
    "class ParticipantProfile:\n",
    "    pid: str\n",
    "    demographic_group_no: int\n",
    "    location: str\n",
    "    occupation: str\n",
    "    gender: str \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrustState:\n",
    "    match_id: str\n",
    "    proposer: ParticipantProfile\n",
    "    responder: ParticipantProfile\n",
    "    transcript: List[Dict] = field(default_factory=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74831c9c-08dd-4a6a-9d3f-e7c5df497398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 2. Load experiment JSON\n",
    "# -----------------------------\n",
    "\n",
    "EXPERIMENT_JSON_PATH = pathlib.Path(\"experiments_v3.json\")\n",
    "with open(EXPERIMENT_JSON_PATH, \"r\") as f:\n",
    "    EXPERIMENTS = json.load(f)\n",
    "\n",
    "EXP = next(e for e in EXPERIMENTS if e.get(\"experiment_id\") == \"gender_trust_1999\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acc53c00-e56a-4603-8c7d-37c5a02b8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_demographic_info(demo_list):\n",
    "    \n",
    "    info = {}\n",
    "\n",
    "    for block in demo_list:\n",
    "        cat = block[\"category\"]\n",
    "\n",
    "        if cat == \"gender\":\n",
    "            gender_dist = {}\n",
    "            for item in block[\"category_info\"]:\n",
    "                gender_dist[item[\"subcategory\"]] = item[\"percentage\"]\n",
    "            info[\"gender_distribution\"] = gender_dist\n",
    "\n",
    "        elif cat == \"location\":\n",
    "            info[\"location\"] = block[\"category_info\"][0][\"subcategory\"]\n",
    "\n",
    "        elif cat == \"occupation\":\n",
    "            info[\"occupation\"] = block[\"category_info\"][0][\"subcategory\"]\n",
    "\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d0c174-aa23-449a-bfce-8587087a71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 3. Participant sampler\n",
    "# -----------------------------\n",
    "\n",
    "def build_participants(exp_json) -> List[ParticipantProfile]:\n",
    "    \n",
    "    participants = []\n",
    "    pid_counter = 0\n",
    "     \n",
    "    for group in exp_json[\"demographic_info\"]:\n",
    "        \n",
    "        n = group[\"num_of_participants\"]\n",
    "        demo = extract_demographic_info(group[\"demographic_info\"])\n",
    "    \n",
    "        gender_dist = demo[\"gender_distribution\"]\n",
    "        male_pct = gender_dist[\"male\"] / 100\n",
    "        female_pct = gender_dist[\"female\"] / 100\n",
    "    \n",
    "        genders = (\n",
    "            [\"male\"] * round(n * male_pct)\n",
    "            + [\"female\"] * round(n * female_pct)\n",
    "        )\n",
    "    \n",
    "        # fix rounding drift\n",
    "        while len(genders) < n:\n",
    "            genders.append(\"male\")\n",
    "        while len(genders) > n:\n",
    "            genders.pop()\n",
    "    \n",
    "        random.shuffle(genders)\n",
    "    \n",
    "        for g in genders:\n",
    "            participants.append(\n",
    "                ParticipantProfile(\n",
    "                    pid=f\"P{pid_counter:04d}\",\n",
    "                    demographic_group_no=group[\"demographic_group_no\"],\n",
    "                    location=demo.get(\"location\", \"unknown\"),\n",
    "                    occupation=demo.get(\"occupation\", \"unknown\"),\n",
    "                    gender=g,\n",
    "                )\n",
    "            )\n",
    "            pid_counter += 1\n",
    "    \n",
    "    assert len(participants) == exp_json[\"total_participants_count\"]\n",
    "    return participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0eb1a08-7e49-44af-af8b-f580c964b491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 186\n",
      "By group: Counter({2: 50, 1: 48, 3: 44, 4: 44})\n",
      "By gender: Counter({'male': 136, 'female': 50})\n"
     ]
    }
   ],
   "source": [
    "participants = build_participants(EXP)\n",
    "\n",
    "print(\"Total:\", len(participants))\n",
    "print(\"By group:\", Counter(p.demographic_group_no for p in participants))\n",
    "print(\"By gender:\", Counter(p.gender for p in participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892060d7-b320-4c49-9c71-ed949d26fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Matchmaker (within-site random pairing)\n",
    "# -----------------------------\n",
    "\n",
    "def make_matches(participants: List[ParticipantProfile]) -> List[TrustState]:\n",
    "    \n",
    "    matches = []\n",
    "    by_group: Dict[int, List[ParticipantProfile]] = {}\n",
    "    \n",
    "    for p in participants:\n",
    "        by_group.setdefault(p.demographic_group_no, []).append(p)\n",
    "        \n",
    "    for gno, plist in by_group.items():\n",
    "        random.shuffle(plist)\n",
    "        assert len(plist) % 2 == 0\n",
    "        \n",
    "        for i in range(0, len(plist), 2):\n",
    "            p1, p2 = plist[i], plist[i + 1]\n",
    "            proposer, responder = random.sample([p1, p2], 2)\n",
    "            \n",
    "            match_id = f\"G{gno}_M{i//2:03d}\"\n",
    "            matches.append(\n",
    "            TrustState(\n",
    "                match_id=match_id,\n",
    "                proposer=proposer,\n",
    "                responder=responder,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec99a756-b8a6-4e14-997a-d9d5e7e6a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proposer_prompt(state: TrustState) -> str:\n",
    "    p = state.proposer\n",
    "    return f\"\"\"\n",
    "You are participating in an economics experiment.\n",
    "\n",
    "About you:\n",
    "- Gender: {p.gender}\n",
    "- Location: {p.location}\n",
    "- Occupation: {p.occupation}\n",
    "\n",
    "You are Player 1.\n",
    "\n",
    "You are given 1000 units of money.\n",
    "You may send any amount between 0 and 1000 to Player 2.\n",
    "Any amount you send will be tripled before Player 2 receives it.\n",
    "Player 2 may return some amount to you.\n",
    "\n",
    "Please:\n",
    "1) Decide how much you want to send.\n",
    "2) Briefly explain your reason in one or two sentences.\n",
    "\n",
    "Respond naturally, as a real participant would.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d5d4b0-34c0-4e7a-86d5-ceac43b5141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responder_prompt(state: TrustState, sent_operational: int) -> str:\n",
    "    r = state.responder\n",
    "    tripled = 3 * sent_operational\n",
    "    total = 1000 + tripled\n",
    "\n",
    "    return f\"\"\"\n",
    "You are participating in an economics experiment.\n",
    "\n",
    "About you:\n",
    "- Gender: {r.gender}\n",
    "- Location: {r.location}\n",
    "- Occupation: {r.occupation}\n",
    "\n",
    "You are Player 2.\n",
    "\n",
    "Player 1 sent you {sent_operational} units.\n",
    "This amount was tripled, so you received {tripled} units.\n",
    "You now have a total of {total} units.\n",
    "\n",
    "You may return any amount between 0 and {total} to Player 1.\n",
    "You keep whatever you do not return.\n",
    "\n",
    "Please:\n",
    "1) Decide how much you want to return.\n",
    "2) Briefly explain your reason in one or two sentences.\n",
    "\n",
    "Respond naturally, as a real participant would.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74025005-a18b-49a3-a1f2-8f7e97deae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_amount_with_llm(\n",
    "    raw_text: str,\n",
    "    role: str,\n",
    "    min_value: int,\n",
    "    max_value: int,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    temperature: float = 0.0,\n",
    ") -> int | None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Extracts a single integer decision from free text using an LLM.\n",
    "    Returns None if extraction fails.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "From the text below, extract the amount of money the person is willing to give\n",
    "(send or return), not any other numbers mentioned.\n",
    "\n",
    "Rules:\n",
    "- The amount must be an integer between {min_value} and {max_value}.\n",
    "- Ignore examples, explanations, or hypothetical numbers.\n",
    "- If multiple amounts are mentioned, choose the one the person commits to giving.\n",
    "- If no such amount is stated, output NONE.\n",
    "\n",
    "Text:\n",
    "\\\"\\\"\\\"\n",
    "{raw_text}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Output exactly one line:\n",
    "AMOUNT: <integer>\n",
    "or\n",
    "AMOUNT: NONE\n",
    "\"\"\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=32,\n",
    "            do_sample=False,   # deterministic for coding\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    answer = decoded[len(prompt):].strip()\n",
    "    \n",
    "    answer = re.sub(r\"```.*?\\n\", \"\", answer, flags=re.DOTALL)\n",
    "    answer = answer.replace(\"```\", \"\").strip()\n",
    "\n",
    "    m = re.search(r\"AMOUNT:\\s*(\\d+|NONE)\", answer, flags=re.IGNORECASE)\n",
    "    \n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    val = m.group(1)\n",
    "\n",
    "    if val.upper() == \"NONE\":\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        val = int(val)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "    if min_value <= val <= max_value:\n",
    "        return val\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fa7ac40-f767-45c0-9f43-01e17381b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(prompt: str, max_new_tokens: int = 64) -> str:\n",
    "    inputs = tok(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.3,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "\n",
    "    text = tok.decode(output[0], skip_special_tokens=True)\n",
    "    return text[len(prompt):].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9dbe2a6-f1b3-46b3-9b56-26459b31d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_match(state: TrustState) -> TrustState:\n",
    "\n",
    "    if state.transcript is None:\n",
    "        state.transcript = []\n",
    "\n",
    "    # --- Proposer ----------------------------------------------------------\n",
    "    p_prompt = proposer_prompt(state)\n",
    "    p_out = run_llm(p_prompt)\n",
    "\n",
    "    sent_operational = extract_amount_with_llm(\n",
    "        raw_text=p_out,\n",
    "        role=\"proposer\",\n",
    "        min_value=0,\n",
    "        max_value=1000,\n",
    "        model=model,\n",
    "        tokenizer=tok,\n",
    "    )\n",
    "\n",
    "    state.transcript.append({\n",
    "        \"role\": \"proposer\",\n",
    "        \"prompt\": p_prompt,\n",
    "        \"output\": p_out,\n",
    "        \"sent_operational\": sent_operational,\n",
    "    })\n",
    "\n",
    "    # If proposer amount is unusable, abort this match\n",
    "    if sent_operational is None:\n",
    "        return state\n",
    "\n",
    "\n",
    "    \n",
    "    # --- Responder -----------------------------------------------------------------\n",
    "    r_prompt = responder_prompt(\n",
    "        state,\n",
    "        sent_operational=sent_operational  \n",
    "    )\n",
    "    r_out = run_llm(r_prompt)\n",
    "\n",
    "    returned_operational = extract_amount_with_llm(\n",
    "        raw_text=r_out,\n",
    "        role=\"responder\",\n",
    "        min_value=0,\n",
    "        max_value=1000 + 3 * sent_operational,\n",
    "        model=model,\n",
    "        tokenizer=tok,\n",
    "    )\n",
    "\n",
    "    state.transcript.append({\n",
    "        \"role\": \"responder\",\n",
    "        \"prompt\": r_prompt,\n",
    "        \"output\": r_out,\n",
    "        \"returned_operational\": returned_operational,\n",
    "    })\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d541aec0-58fd-45ea-a9ce-4649856bee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1_M000: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M001: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M002: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M003: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M004: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M005: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M006: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M007: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M008: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M009: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M010: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M011: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M012: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M013: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M014: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M015: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M016: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M017: male@Nankai University, China → female@Nankai University, China\n",
      "G1_M018: female@Nankai University, China → male@Nankai University, China\n",
      "G1_M019: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M020: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M021: female@Nankai University, China → female@Nankai University, China\n",
      "G1_M022: male@Nankai University, China → male@Nankai University, China\n",
      "G1_M023: male@Nankai University, China → male@Nankai University, China\n",
      "G2_M000: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M001: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M002: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M003: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M004: male@Seoul National University, Korea → female@Seoul National University, Korea\n",
      "G2_M005: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M006: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M007: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M008: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M009: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M010: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M011: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M012: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M013: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M014: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M015: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M016: female@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M017: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M018: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M019: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M020: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M021: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M022: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M023: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G2_M024: male@Seoul National University, Korea → male@Seoul National University, Korea\n",
      "G3_M000: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M001: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M002: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M003: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M004: male@Tokyo University, Japan → female@Tokyo University, Japan\n",
      "G3_M005: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M006: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M007: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M008: male@Tokyo University, Japan → female@Tokyo University, Japan\n",
      "G3_M009: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M010: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M011: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M012: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M013: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M014: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M015: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M016: female@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M017: female@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M018: female@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M019: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G3_M020: male@Tokyo University, Japan → female@Tokyo University, Japan\n",
      "G3_M021: male@Tokyo University, Japan → male@Tokyo University, Japan\n",
      "G4_M000: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M001: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M002: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M003: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M004: male@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M005: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M006: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M007: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M008: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M009: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M010: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M011: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M012: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M013: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M014: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M015: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M016: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M017: female@University of Pennsylvania, United States → male@University of Pennsylvania, United States\n",
      "G4_M018: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M019: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M020: female@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n",
      "G4_M021: male@University of Pennsylvania, United States → female@University of Pennsylvania, United States\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "participants = build_participants(EXP)\n",
    "matches = make_matches(participants)\n",
    "\n",
    "results = []\n",
    "\n",
    "for m in matches: # 186 participants ⇒ 93 matches (2 per match).\n",
    "    m = run_match(m)\n",
    "    results.append(asdict(m))\n",
    "    print(\n",
    "        f\"{m.match_id}: \"\n",
    "        f\"{m.proposer.gender}@{m.proposer.location} → \"\n",
    "        f\"{m.responder.gender}@{m.responder.location}\"\n",
    "    )\n",
    "\n",
    "with open(\"gender_trust.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914eb48-dee2-4cfc-9485-18cf402cbf14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
